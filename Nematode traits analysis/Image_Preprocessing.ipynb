{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e033d6",
   "metadata": {},
   "source": [
    "# Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2464a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy import ndimage as ndi \n",
    "from skimage.transform import rotate, hough_circle, hough_circle_peaks, rescale, resize\n",
    "from skimage import util\n",
    "from skimage import draw\n",
    "from skimage import io, color, data, measure, filters, exposure, img_as_ubyte, img_as_float\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.morphology import binary_dilation, disk, binary_erosion, convex_hull_image, remove_small_objects, erosion, remove_small_holes, dilation\n",
    "from skimage.segmentation import morphological_geodesic_active_contour, inverse_gaussian_gradient, checkerboard_level_set, morphological_chan_vese\n",
    "from skimage.exposure import match_histograms\n",
    "from skimage.segmentation import clear_border, active_contour\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import gaussian, unsharp_mask, threshold_local, threshold_otsu\n",
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "from PIL import ImageFilter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa543e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c37489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_black_part(img):\n",
    "    \n",
    "    hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV) \n",
    "    low_hsv = np.array([0,0,0],dtype = np.uint8)\n",
    "    upper_hsv = np.array([180,255,46],dtype = np.uint8)\n",
    "    mask = cv2.inRange(hsv,low_hsv,upper_hsv)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_qr_points(img):\n",
    "    \n",
    "    qrCodeDetector = cv2.wechat_qrcode_WeChatQRCode(\"QRcode_backbone\\\\detect.prototxt\", \n",
    "                                                    \"QRcode_backbone\\\\detect.caffemodel\", \n",
    "                                                    \"QRcode_backbone\\\\sr.prototxt\", \n",
    "                                                    \"QRcode_backbone\\\\sr.caffemodel\")\n",
    "    qr_info, points = qrCodeDetector.detectAndDecode(img)\n",
    "    \n",
    "    return points, qr_info\n",
    "\n",
    "def get_qr_crop_mask_V2(img, points):\n",
    "\n",
    "    for i in points:\n",
    "        coord1 = i[0]\n",
    "        coord2 = i[1]\n",
    "        coord3 = i[2]\n",
    "        coord4 = i[3]\n",
    "        point1 = (int(coord1[0]), int(coord1[1]))\n",
    "        point2 = (int(coord2[0]), int(coord2[1]))\n",
    "        point3 = (int(coord3[0]), int(coord3[1]))\n",
    "        point4 = (int(coord4[0]), int(coord4[1]))\n",
    "    zero_img = np.zeros(img.shape[:2], np.uint8)\n",
    "    cv2.line(zero_img, point1, point2, (255,255,255), 10)\n",
    "    cv2.line(zero_img, point1, point4, (255,255,255), 10)\n",
    "    cv2.line(zero_img, point3, point2, (255,255,255), 10)\n",
    "    cv2.line(zero_img, point3, point4, (255,255,255), 10)\n",
    "    qr_hull = convex_hull_image(zero_img).astype('uint8')\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(15, 15))\n",
    "    qr_mask = cv2.dilate(qr_hull, kernel)\n",
    "\n",
    "    return qr_mask\n",
    "\n",
    "def display_object_from_original(img, label_img):\n",
    "\n",
    "    mask = label_img > 0\n",
    "\n",
    "    r = img[:, :, 0] * mask\n",
    "    g = img[:, :, 1] * mask\n",
    "    b = img[:, :, 2] * mask\n",
    "\n",
    "    img_temp = np.dstack([r, g, b])\n",
    "    \n",
    "    return img_temp\n",
    "\n",
    "def function_good_match(des1,des2, delta = 0.5):\n",
    "    bfm = cv2.BFMatcher()\n",
    "    matches = bfm.knnMatch(des1, des2, k=2)\n",
    "    good_match = []\n",
    "    for m1, m2 in matches:\n",
    "        if m1.distance < delta * m2.distance:\n",
    "            good_match.append(m1)\n",
    "    return good_match\n",
    "\n",
    "def angle_between(p1, p2, p3):\n",
    "    # calcaulate the angle \n",
    "    v1 = p1 - p2\n",
    "    v2 = p3 - p2\n",
    "    angle = np.math.atan2(np.linalg.det([v1,v2]),np.dot(v1,v2))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def is_rectangle(contour, angle_threshold=10, ratio_threshold=0.2):\n",
    "    # Contour approximation\n",
    "    epsilon = 0.05 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        # check the angle\n",
    "        for i in range(4):\n",
    "            angle = abs(angle_between(approx[i][0], approx[(i+1)%4][0], approx[(i+2)%4][0]))\n",
    "            if abs(angle - 90) > angle_threshold:\n",
    "                return False\n",
    "\n",
    "        # Check the ratio of side lengths\n",
    "        edge_lengths = [np.linalg.norm(approx[i][0] - approx[(i+1)%4][0]) for i in range(4)]\n",
    "        if max(edge_lengths) / min(edge_lengths) > 1 + ratio_threshold:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a265b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir(img_input_folder)    ### 'img_input_folder' refers to the path of the folder to be analyzed; you need to specify it first.\n",
    "\n",
    "if os.path.exists(img_output_folder):   ### 'img_output_folder' refers to the path where the output is saved; you need to specify it first. \n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(img_output_folder)\n",
    "\n",
    "for j in range(len(image_list)):\n",
    "\n",
    "    image_name = image_list[j].split('.')[0]\n",
    "\n",
    "    image_path = os.path.join(img_input_folder, image_list[j])\n",
    "\n",
    "    print(\"*********processing image %s***********\" % (image_list[j]))\n",
    "\n",
    "    output_image_path = os.path.join(img_output_folder, image_name + '.png')\n",
    "\n",
    "    base_image_path = os.path.join(img_input_folder, image_list[0])   ### define the baseline image\n",
    "\n",
    "    base_image = cv2.imread(base_image_path)\n",
    "\n",
    "    base_qr_points, base_qr_info = get_qr_points(base_image)\n",
    "    if base_qr_points != ():\n",
    "    \n",
    "        get_base_qr_mask = get_qr_crop_mask_V2(base_image, base_qr_points)\n",
    "    \n",
    "    else:\n",
    "        base_image_path = os.path.join(img_input_folder, image_list[1])\n",
    "\n",
    "        base_image = cv2.imread(base_image_path)\n",
    "        base_qr_points, base_qr_info = get_qr_points(base_image)\n",
    "        get_base_qr_mask = get_qr_crop_mask_V2(base_image, base_qr_points)\n",
    "\n",
    "    base_qr_part = display_object_from_original(base_image, get_base_qr_mask)\n",
    "    \n",
    "    input_image = cv2.imread(image_path)\n",
    "\n",
    "    qr_points, qr_info = get_qr_points(input_image)\n",
    "\n",
    "    if qr_points!=():\n",
    "        \n",
    "        dst_PT_img = input_image\n",
    "\n",
    "        qr_mask = get_qr_crop_mask_V2(input_image, qr_points)\n",
    "\n",
    "        edge_img = np.logical_xor(qr_mask, binary_erosion(qr_mask, disk(2)))\n",
    "        edge = edge_img.astype(np.uint8)\n",
    "        contours, _ = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            if is_rectangle(cnt)==True:\n",
    "                # Draw the contour\n",
    "                qr_mask = cv2.dilate(qr_mask, disk(2))\n",
    "                qr_part = display_object_from_original(input_image, qr_mask)\n",
    "                img_gray1 = cv2.cvtColor(base_qr_part, cv2.COLOR_BGR2GRAY)\n",
    "                img_gray2 = cv2.cvtColor(qr_part, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                sift= cv2.SIFT_create()\n",
    "\n",
    "                sift_img1 = img_as_ubyte(img_gray1)\n",
    "                sift_img2 = img_as_ubyte(img_gray2)\n",
    "\n",
    "                # Extraction of SIFT feature points and feature descriptions\n",
    "                kp1, des1 = sift.detectAndCompute(sift_img1,None)\n",
    "                kp2, des2 = sift.detectAndCompute(sift_img2,None)\n",
    "\n",
    "                goodMatch = function_good_match(des1,des2)\n",
    "\n",
    "                # Use the KNN algorithm to find the two nearest data points.\n",
    "                # If the ratio of the closest value to the second-closest value is greater than a predefined value,\n",
    "                # Keep this closest value and consider it and the point it matches as a good match.\n",
    "                MIN_MATCH_COUNT = 10\n",
    "\n",
    "                if len(goodMatch)>MIN_MATCH_COUNT:\n",
    "                    src_pts = np.float32([kp1[m.queryIdx].pt for m in goodMatch]).reshape(-1,1,2)\n",
    "                    dst_pts = np.float32([kp2[m.trainIdx].pt for m in goodMatch]).reshape(-1,1,2)\n",
    "\n",
    "                    M_f, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "                    matchesMask = mask.ravel().tolist()\n",
    "\n",
    "                    h,w = sift_img1.shape\n",
    "                    pts_f = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "\n",
    "                    dst = cv2.perspectiveTransform(pts_f, M_f)\n",
    "                    sift_img2 = cv2.polylines(sift_img2, [np.int32(dst)], True, 255,3, cv2.LINE_AA)\n",
    "                else:\n",
    "                    matchesMask = None\n",
    "                                            \n",
    "                dst_PT_img = cv2.warpPerspective(input_image, M_f,(qr_part.shape[1],qr_part.shape[0]),flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        \n",
    "                cv2.imwrite(output_image_path, dst_PT_img)\n",
    "            else:\n",
    "                \n",
    "                continue\n",
    "        \n",
    "    else:\n",
    "\n",
    "        print('can not detect qrcode')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6183ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nematode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
